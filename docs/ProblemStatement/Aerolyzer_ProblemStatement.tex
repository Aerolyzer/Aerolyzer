\documentclass[letterpaper,10pt,draftclsnofoot,onecolumn]{IEEEtran}

\usepackage[margin=0.75in]{geometry}

\def\name{E. Reilly Collins, Sophia Liu, Jesse Hanson \group}
\def\team{Aerolyzer }
\def\assign{Problem Statement}
\def\group{(Group 22)}
\def\course{CS 461 Fall 2016}
% Title page information
\title{\team \assign}
\author{\name}
\setlength{\parindent}{0pt}
\begin{document}
\maketitle
\vspace*{10em}
\centering
\course
\vspace*{4em}
\begin{abstract} 
For the average citizen, getting accurate real-time updates of atmospheric conditions is a challenge.
This difficulty results in limited availability of information about current aerosol content for the general public.
Meanwhile, millions of digital images are taken on mobile phones daily, some of which contain outdoor scenes.
Combining this volume of mobile users' landscape images with camera metadata and existing atmospheric information provides an untapped resource for inferring atmospheric phenomenon.
The purpose of this project is to develop an application that supports the ability to understand content from these digital outdoor images in order to better monitor current aerosol content.
To accomplish this goal, we aim to create a mobile application which consistently feeds users' mobile images into machine learning methods.
Coupling these images and digital metadata with meteorological information will provide the general public with near-real time monitoring of atmospheric conditions.
\end{abstract}

\clearpage
\begin{flushleft}
\section{Problem Definition}
The ability to get real-time updates of atmospheric conditions can be very limited.
Moreover, delayed or inaccurate atmospheric reports can be very inconvenient for those in need of (or who simply want) reliable aerosol content information, as aerosols interact both directly and indirectly with the Earth's radiation budget and climate.
Currently, the available image feature detection software uses a standard shape definition to identify features.
While this is useful, there is a need for a tool that enables feature detection based on an image's color distribution in order to determine the composition of atmospheric aerosol.
Identifying atmospheric conditions based on color is particularly useful for discerning aerosols in sunsets and sunrises: these minute particles can scatter and absorb sunlight, which effectively reddens the sky at dawn and dusk.

\section{Proposed Solution}
The purpose of this project is to develop a tool capable of processing visible images and inferring atmospheric (optical or otherwise) phenomena.
Our image detection will uniquely utilize color distribution within the image to identify features necessary for analyzing aerosol content.
 This goal will be accomplished by developing a full mobile app that employs an open source algorithm translating how the human brain interprets images using RGB values.
Images and other data from available sources will assist in the inferences of atmospheric aerosol composition, as well as aid in determining the type of atmospheric phenomenon the image displays (for example, a sunset or sunrise).
Furthermore, our app will have a "citizen science" component: images will be collected from members of the general public (the app users) as part of a collaborative project with our team in order to analyze aerosol content.
In return, the general public will be able to use the app to determine the current aerosol composition of the atmosphere based on their own mobile images.
This ability to quantify color in images and use the resulting data to determine current aerosol content will provide average citizens with near-real time monitoring of atmospheric conditions.
\section{Performance Metrics}
We will measure whether our solution meets our defined needs and functions by creating (at minimum) a mobile application that correctly identifies sunsets and sunrises in pre-loaded images.
If we are able to determine a sunset/sunrise digital photo using our color detection algorithm, we can continue with processing user-uploaded images and/or identifying other atmospheric phenomenon.
The team will also learn research methodologies and hope to produce a short conference proceeding a paper on the work done in the algorithm. 
\clearpage

\section*{Signatures}

\subsection*{Kim Whitehall} % Suppress section numbering with the *

\begin{tabular}{ l p{10pt} l }
Signature: && \hspace{0.5cm} \makebox[3in]{\hrulefill} \\ \\[5pt]
Date: && \hspace{0.5cm} \today
\end{tabular}

\subsection*{E. Reilly Collins}

\begin{tabular}{ l p{10pt} l }
Signature: && \hspace{0.5cm} \makebox[3in]{\hrulefill} \\ \\[3pt]
Date: && \hspace{0.5cm} \today
\end{tabular}

\subsection*{Sophia Liu}

\begin{tabular}{ l p{10pt} l }
Signature: && \hspace{0.5cm} \makebox[3in]{\hrulefill} \\ \\[3pt]
Date: && \hspace{0.5cm} \today
\end{tabular}

\subsection*{Jesse Hanson}

\begin{tabular}{ l p{10pt} l }
Signature: && \hspace{0.5cm} \makebox[3in]{\hrulefill} \\ \\[3pt]
Date: && \hspace{0.5cm} \today
\end{tabular}
\end{flushleft}
\end{document}
